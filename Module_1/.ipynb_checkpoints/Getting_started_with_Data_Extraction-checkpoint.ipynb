{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a4e05f",
   "metadata": {},
   "source": [
    "## Data sourcing\n",
    "\n",
    "Source data from various source systems and ingest them using python code.\n",
    "\n",
    "1. Parquet files\n",
    "2. CSV files\n",
    "3. APIs\n",
    "4. RDBMS databases\n",
    "5. HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7de7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import certifi\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import urllib3\n",
    "from urllib3 import request\n",
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fce245-6ef2-45dd-8e10-04b54202c3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vicky/Documents/python-etl-example/Building-ETL-Pipelines-with-Python/Chapters/chapter_04\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746175dc",
   "metadata": {},
   "source": [
    "### Sourcing Parquet data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c37682",
   "metadata": {},
   "source": [
    "Please visit the url https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132b5dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:35:40</td>\n",
       "      <td>2022-01-01 00:53:29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:33:43</td>\n",
       "      <td>2022-01-01 00:42:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:53:21</td>\n",
       "      <td>2022-01-01 01:02:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:25:21</td>\n",
       "      <td>2022-01-01 00:35:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:36:48</td>\n",
       "      <td>2022-01-01 01:14:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2022-01-01 00:35:40   2022-01-01 00:53:29              2.0   \n",
       "1         1  2022-01-01 00:33:43   2022-01-01 00:42:07              1.0   \n",
       "2         2  2022-01-01 00:53:21   2022-01-01 01:02:19              1.0   \n",
       "3         2  2022-01-01 00:25:21   2022-01-01 00:35:23              1.0   \n",
       "4         2  2022-01-01 00:36:48   2022-01-01 01:14:20              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           3.80         1.0                  N           142           236   \n",
       "1           2.10         1.0                  N           236            42   \n",
       "2           0.97         1.0                  N           166           166   \n",
       "3           1.09         1.0                  N           114            68   \n",
       "4           4.30         1.0                  N            68           163   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         14.5    3.0      0.5        3.65           0.0   \n",
       "1             1          8.0    0.5      0.5        4.00           0.0   \n",
       "2             1          7.5    0.5      0.5        1.76           0.0   \n",
       "3             2          8.0    0.5      0.5        0.00           0.0   \n",
       "4             1         23.5    0.5      0.5        3.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         21.95                   2.5          0.0  \n",
       "1                    0.3         13.30                   0.0          0.0  \n",
       "2                    0.3         10.56                   0.0          0.0  \n",
       "3                    0.3         11.80                   2.5          0.0  \n",
       "4                    0.3         30.30                   2.5          0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from the Parquet file. We use pandas read_parquet method for ease and speed.\n",
    "df_parquet = pd.read_parquet(\"./data/yellow_tripdata_2022-01.parquet\")\n",
    "df_parquet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2f93c",
   "metadata": {},
   "source": [
    "### Sourcing CSV data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a306a2",
   "metadata": {},
   "source": [
    "Please visit the url https://data.cityofnewyork.us/resource/h9gi-nx95.csv?$limit=500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56007303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_date</th>\n",
       "      <th>crash_time</th>\n",
       "      <th>borough</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location</th>\n",
       "      <th>on_street_name</th>\n",
       "      <th>off_street_name</th>\n",
       "      <th>cross_street_name</th>\n",
       "      <th>...</th>\n",
       "      <th>contributing_factor_vehicle_2</th>\n",
       "      <th>contributing_factor_vehicle_3</th>\n",
       "      <th>contributing_factor_vehicle_4</th>\n",
       "      <th>contributing_factor_vehicle_5</th>\n",
       "      <th>collision_id</th>\n",
       "      <th>vehicle_type_code1</th>\n",
       "      <th>vehicle_type_code2</th>\n",
       "      <th>vehicle_type_code_3</th>\n",
       "      <th>vehicle_type_code_4</th>\n",
       "      <th>vehicle_type_code_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-20T00:00:00.000</td>\n",
       "      <td>1:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.835808</td>\n",
       "      <td>-73.89083</td>\n",
       "      <td>\\n,  \\n(40.835808, -73.89083)</td>\n",
       "      <td>BOSTON ROAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4547589</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-21T00:00:00.000</td>\n",
       "      <td>5:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FDR DRIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4548075</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-14T00:00:00.000</td>\n",
       "      <td>5:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BRONX WHITESTONE BRIDGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4407480</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-13T00:00:00.000</td>\n",
       "      <td>21:35</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11217.0</td>\n",
       "      <td>40.683580</td>\n",
       "      <td>-73.97617</td>\n",
       "      <td>(40.68358, -73.97617)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>620       ATLANTIC AVENUE</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4407147</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-15T00:00:00.000</td>\n",
       "      <td>16:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUTCHINSON RIVER PARKWAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4407665</td>\n",
       "      <td>Station Wagon/Sport Utility Vehicle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                crash_date crash_time   borough  zip_code   latitude  \\\n",
       "0  2022-07-20T00:00:00.000       1:25       NaN       NaN  40.835808   \n",
       "1  2022-07-21T00:00:00.000       5:20       NaN       NaN        NaN   \n",
       "2  2021-04-14T00:00:00.000       5:32       NaN       NaN        NaN   \n",
       "3  2021-04-13T00:00:00.000      21:35  BROOKLYN   11217.0  40.683580   \n",
       "4  2021-04-15T00:00:00.000      16:15       NaN       NaN        NaN   \n",
       "\n",
       "   longitude                       location            on_street_name  \\\n",
       "0  -73.89083  \\n,  \\n(40.835808, -73.89083)               BOSTON ROAD   \n",
       "1        NaN                            NaN                 FDR DRIVE   \n",
       "2        NaN                            NaN   BRONX WHITESTONE BRIDGE   \n",
       "3  -73.97617          (40.68358, -73.97617)                       NaN   \n",
       "4        NaN                            NaN  HUTCHINSON RIVER PARKWAY   \n",
       "\n",
       "  off_street_name                         cross_street_name  ...  \\\n",
       "0             NaN                                       NaN  ...   \n",
       "1             NaN                                       NaN  ...   \n",
       "2             NaN                                       NaN  ...   \n",
       "3             NaN  620       ATLANTIC AVENUE                 ...   \n",
       "4             NaN                                       NaN  ...   \n",
       "\n",
       "   contributing_factor_vehicle_2  contributing_factor_vehicle_3  \\\n",
       "0                    Unspecified                            NaN   \n",
       "1                    Unspecified                            NaN   \n",
       "2                    Unspecified                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   contributing_factor_vehicle_4  contributing_factor_vehicle_5  collision_id  \\\n",
       "0                            NaN                            NaN       4547589   \n",
       "1                            NaN                            NaN       4548075   \n",
       "2                            NaN                            NaN       4407480   \n",
       "3                            NaN                            NaN       4407147   \n",
       "4                            NaN                            NaN       4407665   \n",
       "\n",
       "                    vehicle_type_code1  vehicle_type_code2  \\\n",
       "0                                Sedan               Sedan   \n",
       "1                                Sedan               Sedan   \n",
       "2                                Sedan               Sedan   \n",
       "3                                Sedan                 NaN   \n",
       "4  Station Wagon/Sport Utility Vehicle                 NaN   \n",
       "\n",
       "   vehicle_type_code_3 vehicle_type_code_4 vehicle_type_code_5  \n",
       "0                  NaN                 NaN                 NaN  \n",
       "1                  NaN                 NaN                 NaN  \n",
       "2                  NaN                 NaN                 NaN  \n",
       "3                  NaN                 NaN                 NaN  \n",
       "4                  NaN                 NaN                 NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from the CSV file. We use pandas read_csv method for ease and speed.\n",
    "df_csv = pd.read_csv(\"./data/h9gi-nx95.csv\")\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da41e6",
   "metadata": {},
   "source": [
    "### Sourcing data from APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc77b5",
   "metadata": {},
   "source": [
    "Please make sure to install the certifi library using - pipenv install certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9d0c9d-bf49-4ce2-af7a-0840e420edcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages (from requests) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a061b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crash_date</th>\n",
       "      <th>crash_time</th>\n",
       "      <th>on_street_name</th>\n",
       "      <th>off_street_name</th>\n",
       "      <th>number_of_persons_injured</th>\n",
       "      <th>number_of_persons_killed</th>\n",
       "      <th>number_of_pedestrians_injured</th>\n",
       "      <th>number_of_pedestrians_killed</th>\n",
       "      <th>number_of_cyclist_injured</th>\n",
       "      <th>number_of_cyclist_killed</th>\n",
       "      <th>...</th>\n",
       "      <th>cross_street_name</th>\n",
       "      <th>location.latitude</th>\n",
       "      <th>location.longitude</th>\n",
       "      <th>location.human_address</th>\n",
       "      <th>contributing_factor_vehicle_3</th>\n",
       "      <th>vehicle_type_code_3</th>\n",
       "      <th>contributing_factor_vehicle_4</th>\n",
       "      <th>vehicle_type_code_4</th>\n",
       "      <th>contributing_factor_vehicle_5</th>\n",
       "      <th>vehicle_type_code_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-11T00:00:00.000</td>\n",
       "      <td>2:39</td>\n",
       "      <td>WHITESTONE EXPRESSWAY</td>\n",
       "      <td>20 AVENUE</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-26T00:00:00.000</td>\n",
       "      <td>11:45</td>\n",
       "      <td>QUEENSBORO BRIDGE UPPER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-29T00:00:00.000</td>\n",
       "      <td>6:55</td>\n",
       "      <td>THROGS NECK BRIDGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-11T00:00:00.000</td>\n",
       "      <td>9:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1211      LORING AVENUE</td>\n",
       "      <td>40.667202</td>\n",
       "      <td>-73.8665</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-14T00:00:00.000</td>\n",
       "      <td>8:13</td>\n",
       "      <td>SARATOGA AVENUE</td>\n",
       "      <td>DECATUR STREET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.683304</td>\n",
       "      <td>-73.917274</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-04-14T00:00:00.000</td>\n",
       "      <td>12:47</td>\n",
       "      <td>MAJOR DEEGAN EXPRESSWAY RAMP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-12-14T00:00:00.000</td>\n",
       "      <td>17:05</td>\n",
       "      <td>BROOKLYN QUEENS EXPRESSWAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.709183</td>\n",
       "      <td>-73.956825</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-12-14T00:00:00.000</td>\n",
       "      <td>8:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>344       BAYCHESTER AVENUE</td>\n",
       "      <td>40.86816</td>\n",
       "      <td>-73.83148</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-12-14T00:00:00.000</td>\n",
       "      <td>21:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2047      PITKIN AVENUE</td>\n",
       "      <td>40.67172</td>\n",
       "      <td>-73.8971</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-12-14T00:00:00.000</td>\n",
       "      <td>14:58</td>\n",
       "      <td>3 AVENUE</td>\n",
       "      <td>EAST 43 STREET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.75144</td>\n",
       "      <td>-73.97397</td>\n",
       "      <td>{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                crash_date crash_time                on_street_name  \\\n",
       "0  2021-09-11T00:00:00.000       2:39         WHITESTONE EXPRESSWAY   \n",
       "1  2022-03-26T00:00:00.000      11:45       QUEENSBORO BRIDGE UPPER   \n",
       "2  2022-06-29T00:00:00.000       6:55            THROGS NECK BRIDGE   \n",
       "3  2021-09-11T00:00:00.000       9:35                           NaN   \n",
       "4  2021-12-14T00:00:00.000       8:13               SARATOGA AVENUE   \n",
       "5  2021-04-14T00:00:00.000      12:47  MAJOR DEEGAN EXPRESSWAY RAMP   \n",
       "6  2021-12-14T00:00:00.000      17:05    BROOKLYN QUEENS EXPRESSWAY   \n",
       "7  2021-12-14T00:00:00.000       8:17                           NaN   \n",
       "8  2021-12-14T00:00:00.000      21:10                           NaN   \n",
       "9  2021-12-14T00:00:00.000      14:58                      3 AVENUE   \n",
       "\n",
       "  off_street_name number_of_persons_injured number_of_persons_killed  \\\n",
       "0       20 AVENUE                         2                        0   \n",
       "1             NaN                         1                        0   \n",
       "2             NaN                         0                        0   \n",
       "3             NaN                         0                        0   \n",
       "4  DECATUR STREET                         0                        0   \n",
       "5             NaN                         0                        0   \n",
       "6             NaN                         0                        0   \n",
       "7             NaN                         2                        0   \n",
       "8             NaN                         0                        0   \n",
       "9  EAST 43 STREET                         0                        0   \n",
       "\n",
       "  number_of_pedestrians_injured number_of_pedestrians_killed  \\\n",
       "0                             0                            0   \n",
       "1                             0                            0   \n",
       "2                             0                            0   \n",
       "3                             0                            0   \n",
       "4                             0                            0   \n",
       "5                             0                            0   \n",
       "6                             0                            0   \n",
       "7                             0                            0   \n",
       "8                             0                            0   \n",
       "9                             0                            0   \n",
       "\n",
       "  number_of_cyclist_injured number_of_cyclist_killed  ...  \\\n",
       "0                         0                        0  ...   \n",
       "1                         0                        0  ...   \n",
       "2                         0                        0  ...   \n",
       "3                         0                        0  ...   \n",
       "4                         0                        0  ...   \n",
       "5                         0                        0  ...   \n",
       "6                         0                        0  ...   \n",
       "7                         0                        0  ...   \n",
       "8                         0                        0  ...   \n",
       "9                         0                        0  ...   \n",
       "\n",
       "             cross_street_name location.latitude location.longitude  \\\n",
       "0                          NaN               NaN                NaN   \n",
       "1                          NaN               NaN                NaN   \n",
       "2                          NaN               NaN                NaN   \n",
       "3      1211      LORING AVENUE         40.667202           -73.8665   \n",
       "4                          NaN         40.683304         -73.917274   \n",
       "5                          NaN               NaN                NaN   \n",
       "6                          NaN         40.709183         -73.956825   \n",
       "7  344       BAYCHESTER AVENUE          40.86816          -73.83148   \n",
       "8      2047      PITKIN AVENUE          40.67172           -73.8971   \n",
       "9                          NaN          40.75144          -73.97397   \n",
       "\n",
       "                              location.human_address  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...   \n",
       "4  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...   \n",
       "5                                                NaN   \n",
       "6  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...   \n",
       "7  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...   \n",
       "8  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...   \n",
       "9  {\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\"...   \n",
       "\n",
       "  contributing_factor_vehicle_3 vehicle_type_code_3  \\\n",
       "0                           NaN                 NaN   \n",
       "1                           NaN                 NaN   \n",
       "2                           NaN                 NaN   \n",
       "3                           NaN                 NaN   \n",
       "4                           NaN                 NaN   \n",
       "5                           NaN                 NaN   \n",
       "6                           NaN                 NaN   \n",
       "7                           NaN                 NaN   \n",
       "8                           NaN                 NaN   \n",
       "9                           NaN                 NaN   \n",
       "\n",
       "  contributing_factor_vehicle_4 vehicle_type_code_4  \\\n",
       "0                           NaN                 NaN   \n",
       "1                           NaN                 NaN   \n",
       "2                           NaN                 NaN   \n",
       "3                           NaN                 NaN   \n",
       "4                           NaN                 NaN   \n",
       "5                           NaN                 NaN   \n",
       "6                           NaN                 NaN   \n",
       "7                           NaN                 NaN   \n",
       "8                           NaN                 NaN   \n",
       "9                           NaN                 NaN   \n",
       "\n",
       "  contributing_factor_vehicle_5 vehicle_type_code_5  \n",
       "0                           NaN                 NaN  \n",
       "1                           NaN                 NaN  \n",
       "2                           NaN                 NaN  \n",
       "3                           NaN                 NaN  \n",
       "4                           NaN                 NaN  \n",
       "5                           NaN                 NaN  \n",
       "6                           NaN                 NaN  \n",
       "7                           NaN                 NaN  \n",
       "8                           NaN                 NaN  \n",
       "9                           NaN                 NaN  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get api data from url\n",
    "url = 'https://data.cityofnewyork.us/resource/h9gi-nx95.json?$limit=500'\n",
    "import requests\n",
    "\n",
    "response = requests.get(url)\n",
    "# Check if API is available to retrive the data\n",
    "#apt_status = http.request('GET', url).status\n",
    "print(response.status_code)\n",
    "if response.status_code == 200:\n",
    "    # Sometimes we get certificate error . We shoul never silence this error as this may cause a securirty threat.\n",
    "    # Create a Pool manager that can be used to read the API response \n",
    "    http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where())\n",
    "    data = json.loads(http.request('GET', url).data.decode('utf-8'))\n",
    "    df_api = pd.json_normalize(data)\n",
    "else:\n",
    "    df_api = pd.Dataframe()\n",
    "df_api.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a2b34ba-e7c7-42ad-bf91-628b201b954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vicky/Documents/python-etl-example/Building-ETL-Pipelines-with-Python/Chapters/chapter_04\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282fc78f",
   "metadata": {},
   "source": [
    "### Sourcing Data from RDBMS tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a384b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_title</th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "      <th>uid</th>\n",
       "      <th>director_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43597</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>237000000</td>\n",
       "      <td>150</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>19995</td>\n",
       "      <td>4762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43598</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>300000000</td>\n",
       "      <td>139</td>\n",
       "      <td>2007-05-19</td>\n",
       "      <td>961000000</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>285</td>\n",
       "      <td>4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43599</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>245000000</td>\n",
       "      <td>107</td>\n",
       "      <td>2015-10-26</td>\n",
       "      <td>880674609</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>A Plan No One Escapes</td>\n",
       "      <td>206647</td>\n",
       "      <td>4764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43600</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>250000000</td>\n",
       "      <td>112</td>\n",
       "      <td>2012-07-16</td>\n",
       "      <td>1084939099</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>The Legend Ends</td>\n",
       "      <td>49026</td>\n",
       "      <td>4765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43601</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>260000000</td>\n",
       "      <td>43</td>\n",
       "      <td>2012-03-07</td>\n",
       "      <td>284139100</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>Lost in our world, found in another.</td>\n",
       "      <td>49529</td>\n",
       "      <td>4766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                            original_title     budget  popularity  \\\n",
       "0  43597                                    Avatar  237000000         150   \n",
       "1  43598  Pirates of the Caribbean: At World's End  300000000         139   \n",
       "2  43599                                   Spectre  245000000         107   \n",
       "3  43600                     The Dark Knight Rises  250000000         112   \n",
       "4  43601                               John Carter  260000000          43   \n",
       "\n",
       "  release_date     revenue                                     title  \\\n",
       "0   2009-12-10  2787965087                                    Avatar   \n",
       "1   2007-05-19   961000000  Pirates of the Caribbean: At World's End   \n",
       "2   2015-10-26   880674609                                   Spectre   \n",
       "3   2012-07-16  1084939099                     The Dark Knight Rises   \n",
       "4   2012-03-07   284139100                               John Carter   \n",
       "\n",
       "   vote_average  vote_count  \\\n",
       "0           7.2       11800   \n",
       "1           6.9        4500   \n",
       "2           6.3        4466   \n",
       "3           7.6        9106   \n",
       "4           6.1        2124   \n",
       "\n",
       "                                            overview  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...   \n",
       "1  Captain Barbossa, long believed to be dead, ha...   \n",
       "2  A cryptic message from Bond’s past sends him o...   \n",
       "3  Following the death of District Attorney Harve...   \n",
       "4  John Carter is a war-weary, former military ca...   \n",
       "\n",
       "                                          tagline     uid  director_id  \n",
       "0                     Enter the World of Pandora.   19995         4762  \n",
       "1  At the end of the world, the adventure begins.     285         4763  \n",
       "2                           A Plan No One Escapes  206647         4764  \n",
       "3                                 The Legend Ends   49026         4765  \n",
       "4            Lost in our world, found in another.   49529         4766  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read sqlite query results into a pandas DataFrame\n",
    "with sqlite3.connect(\"./data/movies.sqlite\") as conn:\n",
    "    df = pd.read_sql(\"SELECT * from movies\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab324ee5",
   "metadata": {},
   "source": [
    "# Sourcing data from Webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff92439",
   "metadata": {},
   "source": [
    "Please visit the url https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97c5fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Country/Territory</th>\n",
       "      <th>UN region</th>\n",
       "      <th colspan=\"2\" halign=\"left\">IMF[1][13]</th>\n",
       "      <th colspan=\"2\" halign=\"left\">World Bank[14]</th>\n",
       "      <th colspan=\"2\" halign=\"left\">United Nations[15]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Country/Territory</th>\n",
       "      <th>UN region</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>Year</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World</td>\n",
       "      <td>—</td>\n",
       "      <td>104476432</td>\n",
       "      <td>2023</td>\n",
       "      <td>100562011</td>\n",
       "      <td>2022</td>\n",
       "      <td>96698005</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Americas</td>\n",
       "      <td>26949643</td>\n",
       "      <td>2023</td>\n",
       "      <td>25462700</td>\n",
       "      <td>2022</td>\n",
       "      <td>23315081</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China</td>\n",
       "      <td>Asia</td>\n",
       "      <td>17700899</td>\n",
       "      <td>[n 1]2023</td>\n",
       "      <td>17963171</td>\n",
       "      <td>[n 3]2022</td>\n",
       "      <td>17734131</td>\n",
       "      <td>[n 1]2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Europe</td>\n",
       "      <td>4429838</td>\n",
       "      <td>2023</td>\n",
       "      <td>4072192</td>\n",
       "      <td>2022</td>\n",
       "      <td>4259935</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>4230862</td>\n",
       "      <td>2023</td>\n",
       "      <td>4231141</td>\n",
       "      <td>2022</td>\n",
       "      <td>4940878</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Palau</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>267</td>\n",
       "      <td>2023</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>218</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Kiribati</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>246</td>\n",
       "      <td>2023</td>\n",
       "      <td>223</td>\n",
       "      <td>2022</td>\n",
       "      <td>227</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Nauru</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>150</td>\n",
       "      <td>2023</td>\n",
       "      <td>151</td>\n",
       "      <td>2022</td>\n",
       "      <td>155</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Montserrat</td>\n",
       "      <td>Americas</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "      <td>72</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Tuvalu</td>\n",
       "      <td>Oceania</td>\n",
       "      <td>63</td>\n",
       "      <td>2023</td>\n",
       "      <td>60</td>\n",
       "      <td>2022</td>\n",
       "      <td>60</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country/Territory UN region IMF[1][13]            World Bank[14]  \\\n",
       "    Country/Territory UN region   Forecast       Year       Estimate   \n",
       "0               World         —  104476432       2023      100562011   \n",
       "1       United States  Americas   26949643       2023       25462700   \n",
       "2               China      Asia   17700899  [n 1]2023       17963171   \n",
       "3             Germany    Europe    4429838       2023        4072192   \n",
       "4               Japan      Asia    4230862       2023        4231141   \n",
       "..                ...       ...        ...        ...            ...   \n",
       "209             Palau   Oceania        267       2023              —   \n",
       "210          Kiribati   Oceania        246       2023            223   \n",
       "211             Nauru   Oceania        150       2023            151   \n",
       "212        Montserrat  Americas          —          —              —   \n",
       "213            Tuvalu   Oceania         63       2023             60   \n",
       "\n",
       "               United Nations[15]             \n",
       "          Year           Estimate       Year  \n",
       "0         2022           96698005       2021  \n",
       "1         2022           23315081       2021  \n",
       "2    [n 3]2022           17734131  [n 1]2021  \n",
       "3         2022            4259935       2021  \n",
       "4         2022            4940878       2021  \n",
       "..         ...                ...        ...  \n",
       "209          —                218       2021  \n",
       "210       2022                227       2021  \n",
       "211       2022                155       2021  \n",
       "212          —                 72       2021  \n",
       "213       2022                 60       2021  \n",
       "\n",
       "[214 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data from url\n",
    "df_html = pd.read_html('https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)',match = 'by country')\n",
    "# Let's see how many tables are there with tage ' by county'\n",
    "print(len(df_html)) # There are 4 tables\n",
    "# Let's see the first table\n",
    "df_html[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83dad878-03c5-4aa9-8b69-c11654dcb0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure below packages have been installed \n",
    "# pip install pyarrow\n",
    "# pip install certifi\n",
    "\n",
    "import urllib3\n",
    "from urllib3 import request\n",
    "import certifi\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import logging\n",
    "\n",
    "# define top level module logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def source_data_from_parquet(parquet_file_name):\n",
    "    try:\n",
    "        df_parquet = pd.read_parquet(parquet_file_name)\n",
    "        logger.info(f'{parquet_file_name} : extracted {df_parquet.shape[0]} records from the parguet file')\n",
    "    except Exception as e:\n",
    "        logger.exception( f'{parquet_file_name} : - exception {e} encountered while extracting the parguet file')\n",
    "        df_parquet = pd.DataFrame()\n",
    "    return df_parquet\n",
    "\n",
    "\n",
    "def source_data_from_csv(csv_file_name):\n",
    "    try:\n",
    "        df_csv = pd.read_csv(csv_file_name)\n",
    "        logger.info(f'{csv_file_name} : extracted {df_csv.shape[0]} records from the csv file')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'{csv_file_name} : - exception {e} encountered while extracting the csv_file_name file')\n",
    "        df_csv = pd.DataFrame()\n",
    "    return df_csv\n",
    "\n",
    "def source_data_from_api(api_endpoint):\n",
    "    try:\n",
    "        # Check if API is available to retrive the data\n",
    "        # Sometimes we get certificate error . We should never silence this error as this may cause a securirty threat.\n",
    "        # Create a Pool manager that can be used to read the API response \n",
    "        http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where())\n",
    "        api_response = http.request('GET', api_endpoint)\n",
    "        apt_status = api_response.status\n",
    "        if apt_status == 200:\n",
    "            logger.info(f'{apt_status} - ok : while invoking the api {api_endpoint}')\n",
    "            data = json.loads(api_response.data.decode('utf-8'))\n",
    "            df_api = pd.json_normalize(data)\n",
    "            logger.info(f'{apt_status}- extracted {df_api.shape[0]} records from the csv file')\n",
    "        else:\n",
    "            logger.error(f'{apt_status}- error : while invoking the api {api_endpoint}')\n",
    "            df_api = pd.Dataframe()\n",
    "    except Exception as e:\n",
    "        logger.exception(f'{apt_status} : - exception {e} encountered while reading data from the api')\n",
    "        df_api = pd.DataFrame()\n",
    "    return df_api\n",
    "\n",
    "def source_data_from_table(db_name, table_name):\n",
    "    try:\n",
    "        # Read sqlite query results into a pandas DataFrame\n",
    "        with sqlite3.connect(db_name) as conn:\n",
    "            df_table = pd.read_sql(f\"SELECT * from {table_name}\", conn)\n",
    "            logger.info(f'{db_name}- read {df_table.shape[0]} records from the table: {table_name}')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'{db_name} : - exception {e} encountered while reading data from the table: {table_name}')                 \n",
    "        df_table = pd.DataFrame()\n",
    "    return df_table\n",
    "\n",
    "\n",
    "def source_data_from_webpage(web_page_url,matching_keyword):\n",
    "    try:\n",
    "        # Read webpage table into a pandas DataFrame\n",
    "        df_html = pd.read_html(web_page_url,match = matching_keyword)\n",
    "        df_html = df_html[0]\n",
    "        logger.info(f'{web_page_url}- read {df_html.shape[0]} records from the page: {web_page_url}')\n",
    "    except Exception as e:\n",
    "        logger.exception(f'{web_page_url} : - exception {e} encountered while reading data from the page: {web_page_url}')\n",
    "        df_html = pd.DataFrame()\n",
    "    return df_html\n",
    "\n",
    "def extracted_data():\n",
    "        parquet_file_name = \"./data/yellow_tripdata_2022-01.parquet\"\n",
    "        csv_file_name = \"./data/h9gi-nx95.csv\"\n",
    "        api_endpoint = \"https://data.cityofnewyork.us/resource/h9gi-nx95.json?$limit=500\"\n",
    "        db_name = \"./data/movies.sqlite\"\n",
    "        table_name = \"movies\"\n",
    "        web_page_url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "        matching_keyword = \"by country\"\n",
    "\n",
    "        # Extract data from all source systems\n",
    "        # Now these dataframes are available for loading data into eithter VSA table, PSA table or to be consumed in \n",
    "        # transfromation pipeline.\n",
    "\n",
    "        df_parquet,df_csv,df_api,df_table,df_html = (source_data_from_parquet(parquet_file_name),\n",
    "                                                    source_data_from_csv(csv_file_name),\n",
    "                                                    source_data_from_api(api_endpoint),\n",
    "                                                    source_data_from_table(db_name, table_name),\n",
    "                                                    source_data_from_webpage(web_page_url,matching_keyword))\n",
    "        return df_parquet,df_csv,df_api,df_table,df_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37c8077-b9e2-449c-81be-98875e563b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vicky/Documents/python-etl-example/Building-ETL-Pipelines-with-Python/Chapters/chapter_04\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa7cd2f6-98be-4341-ad48-9f10edcd8f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extraction import extraction_functional_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a313a46-4cf6-42e5-9cd5-f5719c189431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yellow_tripdata_2022-01.parquet : - exception [Errno 2] No such file or directory: 'yellow_tripdata_2022-01.parquet' encountered while extracting the parguet file\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vicky/Documents/python-etl-example/Building-ETL-Pipelines-with-Python/Chapters/chapter_04/extraction/extraction_functional_enhanced.py\", line 20, in source_data_from_parquet\n",
      "    df_parquet = pd.read_parquet(parquet_file_name)\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/parquet.py\", line 670, in read_parquet\n",
      "    return impl.read(\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/parquet.py\", line 265, in read\n",
      "    path_or_handle, handles, filesystem = _get_path_or_handle(\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/parquet.py\", line 139, in _get_path_or_handle\n",
      "    handles = get_handle(\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py\", line 872, in get_handle\n",
      "    handle = open(handle, ioargs.mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'yellow_tripdata_2022-01.parquet'\n",
      "h9gi-nx95.csv : - exception [Errno 2] No such file or directory: 'h9gi-nx95.csv' encountered while extracting the csv_file_name file\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vicky/Documents/python-etl-example/Building-ETL-Pipelines-with-Python/Chapters/chapter_04/extraction/extraction_functional_enhanced.py\", line 30, in source_data_from_csv\n",
      "    df_csv = pd.read_csv(csv_file_name)\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 948, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 611, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1448, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1705, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/common.py\", line 863, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'h9gi-nx95.csv'\n",
      "movies.sqlite : - exception Execution failed on sql 'SELECT * from movies': no such table: movies encountered while reading data from the table: movies\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/sql.py\", line 2262, in execute\n",
      "    cur.execute(sql, *args)\n",
      "sqlite3.OperationalError: no such table: movies\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vicky/Documents/python-etl-example/Building-ETL-Pipelines-with-Python/Chapters/chapter_04/extraction/extraction_functional_enhanced.py\", line 62, in source_data_from_table\n",
      "    df_table = pd.read_sql(f\"SELECT * from {table_name}\", conn)\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/sql.py\", line 654, in read_sql\n",
      "    return pandas_sql.read_query(\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/sql.py\", line 2326, in read_query\n",
      "    cursor = self.execute(sql, params)\n",
      "  File \"/Users/vicky/anaconda3/envs/py39/lib/python3.9/site-packages/pandas/io/sql.py\", line 2274, in execute\n",
      "    raise ex from exc\n",
      "pandas.errors.DatabaseError: Execution failed on sql 'SELECT * from movies': no such table: movies\n"
     ]
    }
   ],
   "source": [
    "df_parquit,_,_,_,_ = extraction_functional_enhanced.extracted_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a883a79-bf35-43f3-adcc-af33c92d0919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_data_from_parquet(parquet_file_name):\n",
    "    try:\n",
    "        df_parquet = pd.read_parquet(parquet_file_name)\n",
    "        logger.info(f'{parquet_file_name} : extracted {df_parquet.shape[0]} records from the parguet file')\n",
    "    except Exception as e:\n",
    "        logger.exception( f'{parquet_file_name} : - exception {e} encountered while extracting the parguet file')\n",
    "        df_parquet = pd.DataFrame()\n",
    "    return df_parquet\n",
    "\n",
    "df = source_data_from_parquet(\"./data/yellow_tripdata_2022-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90b04094-b54d-42a2-8d4b-762ee88b1352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:35:40</td>\n",
       "      <td>2022-01-01 00:53:29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:33:43</td>\n",
       "      <td>2022-01-01 00:42:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:53:21</td>\n",
       "      <td>2022-01-01 01:02:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:25:21</td>\n",
       "      <td>2022-01-01 00:35:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:36:48</td>\n",
       "      <td>2022-01-01 01:14:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2022-01-01 00:35:40   2022-01-01 00:53:29              2.0   \n",
       "1         1  2022-01-01 00:33:43   2022-01-01 00:42:07              1.0   \n",
       "2         2  2022-01-01 00:53:21   2022-01-01 01:02:19              1.0   \n",
       "3         2  2022-01-01 00:25:21   2022-01-01 00:35:23              1.0   \n",
       "4         2  2022-01-01 00:36:48   2022-01-01 01:14:20              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           3.80         1.0                  N           142           236   \n",
       "1           2.10         1.0                  N           236            42   \n",
       "2           0.97         1.0                  N           166           166   \n",
       "3           1.09         1.0                  N           114            68   \n",
       "4           4.30         1.0                  N            68           163   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         14.5    3.0      0.5        3.65           0.0   \n",
       "1             1          8.0    0.5      0.5        4.00           0.0   \n",
       "2             1          7.5    0.5      0.5        1.76           0.0   \n",
       "3             2          8.0    0.5      0.5        0.00           0.0   \n",
       "4             1         23.5    0.5      0.5        3.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         21.95                   2.5          0.0  \n",
       "1                    0.3         13.30                   0.0          0.0  \n",
       "2                    0.3         10.56                   0.0          0.0  \n",
       "3                    0.3         11.80                   2.5          0.0  \n",
       "4                    0.3         30.30                   2.5          0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6022ee-63d4-419c-9216-6399255124a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
